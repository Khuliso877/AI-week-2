{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11G5bzTUM_74t1nA17a4Uh3AI2IgdI-9g",
      "authorship_tag": "ABX9TyPPp8xtFOJ9RtKaTbD1nhd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khuliso877/AI-week-2/blob/main/week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj1Rbrz9hIzN",
        "outputId": "fe7f9187-ffa9-4236-9290-52367e18fc18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (13512, 28)\n",
            "Error: Required columns ('year', 'co2_emissions_per_capita', 'gdp_per_capita') not found in the Excel file.\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import requests  # For real-time API integration\n",
        "# import streamlit as st # Removed Streamlit as it doesn't run directly in Colab\n",
        "\n",
        "# Step 1: Load and Preprocess Data\n",
        "# Load data from Excel file\n",
        "try:\n",
        "    data = pd.read_excel('climate-change-excel-4-6-mb-.xls')\n",
        "    print(\"Dataset shape:\", data.shape)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'climate-change-excel-4-6-mb-.xls' not found. Please ensure the file is in the correct path.\")\n",
        "    # You might want to exit or handle this error more gracefully in a real application\n",
        "    exit()\n",
        "\n",
        "\n",
        "# Assuming the Excel file has 'year', 'co2_emissions_per_capita', and 'gdp_per_capita' columns\n",
        "# Adapt column names if necessary based on your Excel file\n",
        "# data = data.rename(columns={'your_year_column': 'year', 'your_co2_column': 'co2_emissions_per_capita', 'your_gdp_column': 'gdp_per_capita'})\n",
        "\n",
        "\n",
        "data = data.dropna()  # Clean: Drop missing\n",
        "scaler = StandardScaler()\n",
        "# Check if the columns exist before scaling\n",
        "if 'year' in data.columns and 'gdp_per_capita' in data.columns and 'co2_emissions_per_capita' in data.columns:\n",
        "    data[['year', 'gdp_per_capita']] = scaler.fit_transform(data[['year', 'gdp_per_capita']])  # Normalize features\n",
        "    X = data[['year', 'gdp_per_capita']]  # Features\n",
        "    y = data['co2_emissions_per_capita']  # Target\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Split 80/20\n",
        "\n",
        "    # Step 2: Train Models (Compare Linear Regression vs. Random Forest)\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    }\n",
        "    predictions = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        predictions[name] = y_pred\n",
        "        print(f\"{name} - MAE: {mae:.2f}, R²: {r2:.2f}\")\n",
        "\n",
        "    best_model = models['Random Forest']\n",
        "\n",
        "    # Step 3: Forecast Future Emissions (2025-2030)\n",
        "    # Assuming a GDP growth of 12000 for future years. Adjust if needed.\n",
        "    future_years_data = np.array([[year, 12000] for year in range(2025, 2031)])\n",
        "    future_years_scaled = scaler.transform(future_years_data)\n",
        "    future_emissions = best_model.predict(future_years_scaled)\n",
        "    print(\"Forecasted CO2 (tons/capita):\", future_emissions)\n",
        "\n",
        "    # Step 4: Evaluate & Visualize\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(y_test, predictions['Random Forest'], alpha=0.5)\n",
        "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "    plt.xlabel('Actual CO2'); plt.ylabel('Predicted CO2'); plt.title('Actual vs Predicted')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    # Need to inverse transform the 'year' column for plotting\n",
        "    historical_years = scaler.inverse_transform(data[['year', 'gdp_per_capita']])[:, 0]\n",
        "    plt.plot(historical_years, y.values, label='Historical', color='blue')\n",
        "    plt.plot(range(2025, 2031), future_emissions, label='Forecast', color='red', marker='o')\n",
        "    plt.xlabel('Year'); plt.ylabel('CO2 per Capita'); plt.legend(); plt.title('Emissions Forecast')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('emissions_forecast.png')  # For report/presentation\n",
        "    plt.show()\n",
        "\n",
        "    # Step 5: Integrate Real-Time Data (e.g., Weather via Open-Meteo API)\n",
        "    # This part will only print the temperature anomaly if executed outside of a Streamlit environment\n",
        "    # Proxy: Global temp anomaly affects emissions (e.g., higher temps = more AC = more emissions)\n",
        "    # Define the URL for the Open-Meteo API - Example URL, you might need to adjust parameters\n",
        "    url = \"/content/climate-change-excel-4-6-mb-.xls\"\n",
        "\n",
        "    def get_temp_anomaly():\n",
        "        try:\n",
        "            response = requests.get(url).json()\n",
        "            # Assuming a baseline temperature of 14C, adjust if needed\n",
        "            recent_temp = np.mean(response['daily']['temperature_2m_mean'][-7:]) - 14\n",
        "            return recent_temp * 0.1  # Simple adjustment factor\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching temperature data: {e}\")\n",
        "            return 0.0 # Return 0 if there's an error\n",
        "\n",
        "    # For non-Streamlit run:\n",
        "    adjustment = get_temp_anomaly()\n",
        "    adjusted_forecast = future_emissions + adjustment\n",
        "    print(f\"Adjusted Forecast (w/ Temp Anomaly {adjustment:.2f}): {adjusted_forecast}\")\n",
        "\n",
        "else:\n",
        "    print(\"Error: Required columns ('year', 'co2_emissions_per_capita', 'gdp_per_capita') not found in the Excel file.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f91bdc0f",
        "outputId": "8cf9d66d-0a4a-4d0d-e11b-a5d3fcf2a764"
      },
      "source": [
        "%pip install streamlit"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.7.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qYPDVmGrt3VC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}